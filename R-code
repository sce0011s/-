options(scipen=4)
library(xlsx)
library(openxlsx)
library(readxl)
library(dplyr)
library(stringr)
library(lubridate)
library(car)
library(GGally)
library(rpart)
library(rpart.plot)
library(randomForest)
library(e1071)
library(MASS)
library(ggplot2)
library(reshape2)
library(car)
library(nlme)
library(partykit)
library(caret)
library(lmtest)
library(parallel)
library(snow)
#######################################################################################################################################
data <- read.xlsx("housing_data.xlsx") #讀取資料
#選取分析用資料
data_analysis <- data[(str_detect(data$remark,"親友")==0 | is.na(str_detect(data$remark,"親友"))) & data$objtran %in% c(3,4,5) & data$buildingtype %in% c(2,3,6,7,8,12),c(1,2,4,12,13,14,16,17,18,19,20,21,23,24,25,29,30,31,32,33)] #篩選資料及變數
data_analysis <- data_analysis[data_analysis$unitprice!=0,]
summary(data_analysis)
data_analysis <- data_analysis[(data_analysis$unitprice %in% unique(boxplot(data_analysis$unitprice,plot = F)$out))==0,] #去除price離群值資料(小於Q1-1.5IQR或大於Q3+1.5IQR)
set.seed(830527)
index<-sample(1:nrow(data_analysis),size=trunc(nrow(data_analysis)*0.2))
training_data <- data_analysis[-index,] #訓練資料
test_data <- data_analysis[index,] #測試資料

#RMSE function
########################################################################################################################################
rmse <- function(x){
  testing <- sqrt(sum((test_data$unitprice-predict(x,test_data))^2)/length(test_data$unitprice))
  training <- sqrt(sum((training_data$unitprice-predict(x,training_data))^2)/length(training_data$unitprice))
  return(c("testing"=testing,"training"=training))
}

#迴歸模型
########################################################################################################################################
lm_model <- lm(unitprice~.,training_data)
qqnorm(lm_model$residuals);qqline(lm_model$residuals)
summary(lm_model)
rmse(lm_model) #test:38873.11,train:39091.54
t <- boxcox(lm_model)$x[which.max(boxcox(lm_model)$y)]
boxcox_lm_model <- lm((unitprice^t-1)/t~.,training_data)
qqnorm(boxcox_lm_model$residuals);qqline(boxcox_lm_model$residuals)
summary(boxcox_lm_model)
sqrt(sum((test_data$unitprice-(predict(boxcox_lm_model,test_data)*t+1)^(1/t))^2)/length(test_data$unitprice)) #38762.98
sqrt(sum((training_data$unitprice-(predict(boxcox_lm_model,training_data)*t+1)^(1/t))^2)/length(training_data$unitprice)) #38998.77

#regreesion tree
#######################################################################################################################################
#cp:決定當新規則加入，改善模型相對誤差(x-val relative value)的程度如沒有大於cp值，則不加入該規則
cpu.cores <- detectCores()
cl = makeCluster(cpu.cores,type='SOCK')
clusterExport(cl,c("rpart","training_data","rmse","test_data"))
tree_model = parSapply(cl,X=seq(0.1,0.001,-0.001),FUN=function(cp){list(rpart(unitprice~.,data = training_data,method = "anova",cp=cp))})
tree_rmse <- parSapply(cl,tree_model,FUN=function(x){list(rmse(x))})
stopCluster(cl)
tree_rmse <- do.call(rbind,tree_rmse) %>% as.data.frame()
tree_rmse$cp <- seq(0.1,0.001,-0.001)

ggplot()+
  geom_line(data=tree_rmse,aes(x=cp,y=testing,colour="testing"),size=1)+
  geom_line(data=tree_rmse,aes(x=cp,y=training,colour="training"),size=1)+
  scale_x_reverse()+
  scale_color_manual(name="",values=c("testing"="red","training"="blue"))+
  scale_y_continuous("rmse")

tree_model1 <- rpart(unitprice~.,data = training_data,method = "anova",cp=0)
rpart.plot(tree_model1)
tree_model2 <- rpart(unitprice~.,data = training_data,method = "anova",cp=0.01)
rpart.plot(tree_model2)
tree_model3 <- rpart(unitprice~.,data = training_data,method = "anova",cp=0.1)
rpart.plot(tree_model3)

plotcp(tree_model1) #將CP設為0後再進行修樹,利用x-val relative error最小值選取適當cp
CP = tree_model1$cptable[which.min(tree_model1$cptable[,"xerror"]),"CP"] #0.0001336516
tree_model_final <- rpart(unitprice~.,data = training_data,method = "anova",cp=CP)
rpart.plot(tree_model_final)

rmse(tree_model_final) #testing=35217.29 training=30729.79

#randomforest
#######################################################################################################################################
#ntree:模型使用樹的數量,預設500
#mtry:隨機抽取的變數數量,預設mtry=p/3=6

cpu.cores <- detectCores()
cl = makeCluster(cpu.cores,type='SOCK')
clusterExport(cl,c("randomForest","training_data","rmse","test_data"))
forest_model <- parSapply(cl,X=seq(10,500,10),FUN=function(ntree){list(randomForest(unitprice~.,data=training_data,ntree=ntree))})
forest_rmse <- parSapply(cl,forest_model,FUN=function(x){list(rmse(x))})
stopCluster(cl)
forest_rmse <- do.call(rbind,forest_rmse) %>% as.data.frame()
forest_rmse$ntree <- seq(10,500,10)

ggplot()+
  geom_line(data=forest_rmse,aes(x=ntree,y=testing,colour="testing"),size=1)+
  geom_line(data=forest_rmse,aes(x=ntree,y=training,colour="training"),size=1)+
  scale_color_manual(name="",values=c("testing"="red","training"="blue"))+
  scale_y_continuous("rmse")

#ntree>100時rmse收斂，取ntree=100

cpu.cores <- detectCores()
cl = makeCluster(cpu.cores,type='SOCK')
clusterExport(cl,c("randomForest","training_data","rmse","test_data"))
forest_model <- parSapply(cl,X=seq(4,15,1),FUN=function(mtry){list(randomForest(unitprice~.,data=training_data,ntree=100,mtry=mtry))})
forest_rmse <- parSapply(cl,forest_model,FUN=function(x){list(rmse(x))})
stopCluster(cl)
forest_rmse <- do.call(rbind,forest_rmse) %>% as.data.frame()
forest_rmse$mtry <- seq(4,15,1)

ggplot()+
  geom_line(data=forest_rmse,aes(x=mtry,y=testing,colour="testing"),size=1)+
  geom_line(data=forest_rmse,aes(x=mtry,y=training,colour="training"),size=1)+
  scale_color_manual(name="",values=c("testing"="red","training"="blue"))+
  scale_y_continuous("rmse")

#mtry=7時rmse最小，取mtry=7

forest_model_final <- randomForest(unitprice~.,data=training_data,ntree=100,mtry=7)
rmse(forest_model_final) #test:29995.07,train:14890.49

#svm
#######################################################################################################################################
#cost:越大則容錯度越少,也越少support vectors,越容易overfitting,預設1
#epsilon:越大則support vectors數量越少,預設0.1
#kernel:預設為RBF(radial basis function kernel)

cpu.cores <- detectCores()
cl = makeCluster(cpu.cores,type='SOCK')
clusterExport(cl,c("svm","training_data","rmse","test_data"))
svm_model <- parSapply(cl,X=c(2^-5,2^-1,2^3,2^7,2^11,2^15),FUN=function(cost){list(svm(unitprice~.,data=training_data,cost=cost))})
svm_rmse <- parSapply(cl,svm_model,FUN=function(x){list(rmse(x))})
stopCluster(cl)
svm_rmse <- do.call(rbind,svm_rmse) %>% as.data.frame()
svm_rmse$cost <- c(2^-5,2^-1,2^3,2^7,2^11,2^15)

ggplot()+
  geom_line(data=svm_rmse,aes(x=cost,y=testing,colour="testing"),size=1)+
  geom_line(data=svm_rmse,aes(x=cost,y=training,colour="training"),size=1)+
  scale_color_manual(name="",values=c("testing"="red","training"="blue"))+
  scale_y_continuous("rmse")

#cost=2^7=128時對測試資料有最小rmse34413.14，取cost=128

cpu.cores <- detectCores()
cl = makeCluster(cpu.cores,type='SOCK')
clusterExport(cl,c("svm","training_data","rmse","test_data"))
svm_model <- parSapply(cl,X=c(0.01,0.1,0.5,1),FUN=function(epsilon){list(svm(unitprice~.,data=training_data,cost=128,epsilon=epsilon))})
svm_rmse <- parSapply(cl,svm_model,FUN=function(x){list(rmse(x))})
stopCluster(cl)
svm_rmse <- do.call(rbind,svm_rmse) %>% as.data.frame()
svm_rmse$epsilon <- c(0.01,0.1,0.5,1)

ggplot()+
  geom_line(data=svm_rmse,aes(x=epsilon,y=testing,colour="testing"),size=1)+
  geom_line(data=svm_rmse,aes(x=epsilon,y=training,colour="training"),size=1)+
  scale_color_manual(name="",values=c("testing"="red","training"="blue"))+
  scale_y_continuous("rmse")

#epsilon=0.5時對測試資料有最小rmse，取epsilon=0.5

svm_model_final <- svm(unitprice~.,data=training_data,cost=128,epsilon=0.5)
rmse(svm_model_final) #testing=34265.25,training=31837.79

test_data$unitprice_lm <- (predict(boxcox_lm_model,test_data)*t+1)^(1/t)
test_data$unitprice_tree <- predict(tree_model_final,test_data)
test_data$unitprice_forest <- predict(forest_model_final,test_data)
test_data$unitprice_svm <- predict(svm_model_final,test_data)

#####################################################################################################################################
#結果比較
unitprice <- reshape2::melt(test_data[,c(13,21,22,23,24)])
ggplot(data = unitprice)+
  geom_boxplot(aes(x=variable,y=value))+
  labs(title="Box plot of testing data",y="unitprice")+
  theme(plot.title=element_text(hjust = 0.5,face="bold",size=15))
